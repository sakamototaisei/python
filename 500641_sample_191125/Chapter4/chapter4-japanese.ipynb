{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 日本語の文章を生成しよう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 28 日本語を形態素解析してみましょう\n",
    "\n",
    "### 手順パート: Janomeで日本語を形態素解析する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<janome.tokenizer.Tokenizer at 0x1063af550>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "t = Tokenizer()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '東京都でおいしいビールを飲もう。'\n",
    "tokens = t.tokenize(text)\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "東京\t名詞,固有名詞,地域,一般,*,*,東京,トウキョウ,トーキョー\n",
      "都\t名詞,接尾,地域,*,*,*,都,ト,ト\n",
      "で\t助詞,格助詞,一般,*,*,*,で,デ,デ\n",
      "おいしい\t形容詞,自立,*,*,形容詞・イ段,基本形,おいしい,オイシイ,オイシイ\n",
      "ビール\t名詞,一般,*,*,*,*,ビール,ビール,ビール\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "飲も\t動詞,自立,*,*,五段・マ行,未然ウ接続,飲む,ノモ,ノモ\n",
      "う\t助動詞,*,*,*,不変化型,基本形,う,ウ,ウ\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n"
     ]
    }
   ],
   "source": [
    "# 文章を分割する\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['東京', '都', 'で', 'おいしい', 'ビール', 'を', '飲も', 'う', '。']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.tokenize(text, wakati=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 29 自然言語処理で使用されるモデルやアルゴリズムを知りましょう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 手順パート: Bag of Wordsのデータを作ってみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['おいしい', 'ビール', 'を', '飲む'],\n",
       " ['コーヒー', 'を', '飲む'],\n",
       " ['おいしい', 'クラフト', 'ビール', 'を', '買う']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 複数の文章を単語に分割する\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "t = Tokenizer()  # ❶ Tokenizerのインスタンスを生成\n",
    "sentences = [  # ❷ 対象となる文章のリスト\n",
    "    'おいしいビールを飲む', 'コーヒーを飲む', 'おいしいクラフトビールを買う'\n",
    "]\n",
    "\n",
    "words_list = []\n",
    "for sentence in sentences:\n",
    "    words_list.append(t.tokenize(sentence, wakati=True))  # ❹ 文章を分かち書き\n",
    "words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['おいしい', 'ビール', 'を', '飲む', 'コーヒー', 'クラフト', '買う']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一意な単語のリストを作成する\n",
    "unique_words = []\n",
    "for words in words_list:  # ❶各単語を取り出す\n",
    "    for word in words:\n",
    "        if word not in unique_words:  # ❷存在しなければ追加\n",
    "            unique_words.append(word)\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 0, 0, 0], [0, 0, 1, 1, 1, 0, 0], [1, 1, 1, 0, 0, 1, 1]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bag of Words のデータを作成する\n",
    "bow_list = []\n",
    "for words in words_list:\n",
    "    bag_of_words = []  # ❶ 1文章のBag of Wordsを格納する\n",
    "    for unique_word in unique_words:\n",
    "        num = words.count(unique_word)  # ❷ 一意な単語の出現回数を数える\n",
    "        bag_of_words.append(num)\n",
    "    bow_list.append(bag_of_words)\n",
    "bow_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.28768207245178085,\n",
       " 0.28768207245178085,\n",
       " 0.0,\n",
       " 0.28768207245178085,\n",
       " 0.6931471805599453,\n",
       " 0.6931471805599453,\n",
       " 0.6931471805599453]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDFを計算する\n",
    "from math import log  # ❶ logをインポート\n",
    "num_of_sentences = len(sentences)\n",
    "idf = []\n",
    "for i in range(len(unique_words)):  # ❷ 一意な単語分繰り返す\n",
    "    count = 0\n",
    "    for bow in bow_list:  # ❸ Bag of Wordsに存在すれば1を足す\n",
    "        if bow[i] > 0:\n",
    "            count += 1\n",
    "    idf.append(log((num_of_sentences + 1) / (count + 1)))  # ❹ 単語のIDFを計算する\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.3333333333333333,\n",
       " 0.42922735748392693,\n",
       " 0.5643823935199818,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDFを計算する\n",
    "bow = bow_list[1]  # ❶「コーヒーを飲む」のBag of Words\n",
    "num_of_words = sum(bow)  # ❷ 1文章の単語の数\n",
    "tfidf = []\n",
    "for i, value in enumerate(bow):\n",
    "    tf = value / num_of_words  # ❸ TFを取得\n",
    "    tfidf.append(tf * (idf[i] + 1))  # ❹ TF-IDFを取得\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>おいしい</th>\n",
       "      <th>ビール</th>\n",
       "      <th>を</th>\n",
       "      <th>飲む</th>\n",
       "      <th>コーヒー</th>\n",
       "      <th>クラフト</th>\n",
       "      <th>買う</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   おいしい  ビール  を  飲む  コーヒー  クラフト  買う\n",
       "0     1    1  1   1     0     0   0\n",
       "1     0    0  1   1     1     0   0\n",
       "2     1    1  1   0     0     1   1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(bow_list, columns=unique_words)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 32 マルコフ連鎖用の辞書データを作成しましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 天気予報の各状態を表すデータ\n",
    "weather_data = {\n",
    "    '晴れ': {\n",
    "        'next_weather_types': ['晴れ', '曇り', '雨'],  # 遷移先の天気のリスト\n",
    "        'weights': [0.6, 0.3, 0.1],  # それぞれの天気に遷移する割合（重み）\n",
    "    },\n",
    "    '曇り': {'next_weather_types': ['晴れ', '曇り', '雨'], 'weights': [0.3, 0.5, 0.2]},\n",
    "    '雨': {'next_weather_types': ['晴れ', '曇り', '雨'], 'weights': [0.2, 0.3, 0.5]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'晴れ': 581, '曇り': 307, '雨': 112}\n"
     ]
    }
   ],
   "source": [
    "# 状態を表すデータから「晴れ」の次の天気を重みありでランダムに取り出す\n",
    "import random\n",
    "\n",
    "next_weather_types = weather_data['晴れ']['next_weather_types']\n",
    "weights = weather_data['晴れ']['weights']\n",
    "\n",
    "count = {'晴れ': 0, '曇り': 0, '雨': 0}\n",
    "for i in range(1000):  # 重みづけを確認するために1000回天気を取り出す\n",
    "    weather = random.choices(next_weather_types, weights=weights)[0]  # リストで返るので先頭を取り出す\n",
    "    count[weather] += 1  # 出現回数を数える\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['晴れ', '晴れ', '晴れ', '晴れ', '晴れ', '晴れ', '曇り', '雨', '晴れ', '雨', '雨']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 天気のマルコフ連鎖を生成する\n",
    "\n",
    "current_weather = '晴れ'\n",
    "markov_weather_list = [current_weather]  # 天気のリストを格納する領域\n",
    "for i in range(10):\n",
    "    next_weather_types = weather_data[current_weather]['next_weather_types']  # 次の状態（天気）と重みを取得\n",
    "    weights = weather_data[current_weather]['weights']\n",
    "    current_weather = random.choices(next_weather_types, weights=weights)[0]  # 次の状態（天気）をランダムに取得\n",
    "    markov_weather_list.append(current_weather)  # 天気を追加\n",
    "markov_weather_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 手順パート: テキストからマルコフ連鎖の辞書データを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['__BEGIN__', 'おいしい', 'ビール'],\n",
       " ['おいしい', 'ビール', 'を'],\n",
       " ['ビール', 'を', '飲も'],\n",
       " ['を', '飲も', 'う'],\n",
       " ['飲も', 'う', '__END__']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1つの文を3単語ずつの組にする\n",
    "\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "BEGIN = '__BEGIN__'  # 文の開始マーク\n",
    "END = '__END__'  # 文の終了マーク\n",
    "\n",
    "sentence = 'おいしいビールを飲もう'\n",
    "\n",
    "t = Tokenizer()\n",
    "words = t.tokenize(sentence, wakati=True)  # ❶ 文を単語に分かち書きする\n",
    "words = [BEGIN] + words + [END]  # ❷ 前後に開始、終了マークを追加する\n",
    "\n",
    "three_words_list = []\n",
    "for i in range(len(words) - 2):\n",
    "    three_words_list.append(words[i:i+3])\n",
    "three_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('__BEGIN__', 'おいしい', 'ビール'): 2,\n",
       "         ('おいしい', 'ビール', 'を'): 1,\n",
       "         ('ビール', 'を', '飲も'): 2,\n",
       "         ('を', '飲も', 'う'): 2,\n",
       "         ('飲も', 'う', '__END__'): 2,\n",
       "         ('__BEGIN__', 'ビール', 'を'): 1,\n",
       "         ('おいしい', 'ビール', 'は'): 1,\n",
       "         ('ビール', 'は', '生'): 1,\n",
       "         ('は', '生', '__END__'): 1})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 複数の文章から単語の組の出現回数を数える\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def get_three_words_list(sentence):  # ❶ 関数にする\n",
    "    \"\"\"文章を3単語の組にして返す\"\"\"\n",
    "    t = Tokenizer()\n",
    "    words = t.tokenize(sentence, wakati=True)\n",
    "    words = [BEGIN] + words + [END]\n",
    "    three_words_list = []\n",
    "    for i in range(len(words) - 2):\n",
    "        three_words_list.append(tuple(words[i:i+3]))\n",
    "    return three_words_list\n",
    "\n",
    "sentences = ['おいしいビールを飲もう', 'ビールを飲もう', 'おいしいビールは生']\n",
    "three_words_list = []\n",
    "for sentence in sentences:  # ❷ 複数の文を順番に処理\n",
    "    three_words_list += get_three_words_list(sentence)\n",
    "three_words_count = Counter(three_words_list)  # ❸ 出現回数を数える\n",
    "three_words_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('__BEGIN__', 'おいしい'): {'words': ['ビール'], 'weights': [2]},\n",
       " ('おいしい', 'ビール'): {'words': ['を', 'は'], 'weights': [1, 1]},\n",
       " ('ビール', 'を'): {'words': ['飲も'], 'weights': [2]},\n",
       " ('を', '飲も'): {'words': ['う'], 'weights': [2]},\n",
       " ('飲も', 'う'): {'words': ['__END__'], 'weights': [2]},\n",
       " ('__BEGIN__', 'ビール'): {'words': ['を'], 'weights': [1]},\n",
       " ('ビール', 'は'): {'words': ['生'], 'weights': [1]},\n",
       " ('は', '生'): {'words': ['__END__'], 'weights': [1]}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文章用の辞書データを作成する\n",
    "\n",
    "def generate_markov_dict(three_words_count):\n",
    "    \"\"\"マルコフ連鎖での文章生成用の辞書データを生成する\"\"\"\n",
    "    markov_dict = {}\n",
    "    for three_words, count in three_words_count.items():\n",
    "        two_words = three_words[:2]  # ❶ 「前半2つの単語」と「次の単語」に分割\n",
    "        next_word = three_words[2]\n",
    "        if two_words not in markov_dict: # ❷ 辞書に存在しない場合は空データを生成\n",
    "            markov_dict[two_words] = {'words': [], 'weights': []}\n",
    "        markov_dict[two_words]['words'].append(next_word)  # ❸ 次の単語と回数を追加\n",
    "        markov_dict[two_words]['weights'].append(count)\n",
    "    return markov_dict\n",
    "\n",
    "markov_dict = generate_markov_dict(three_words_count)\n",
    "markov_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 33 マルコフ連鎖で文章を自動生成しましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'あ': 2, 'え': 2, 'い': 1, 'う': 1, 'お': 2}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'あえいうえおあお'\n",
    "d = {}\n",
    "for char in sentence:  # 文字ごとに分割\n",
    "    if char in d:\n",
    "        d[char] += 1\n",
    "    else:  # 辞書に存在しない場合は初期値を指定\n",
    "        d[char] = 1\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'あ': 2, 'え': 2, 'い': 1, 'う': 1, 'お': 2})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "sentence = 'あえいうえおあお'\n",
    "dd = defaultdict(int)  # デフォルト関数にintを指定\n",
    "for char in sentence:\n",
    "    dd[char] += 1  # 辞書に登録してないキーでも加算が可能\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 手順パート: 辞書データから文章を自動生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'おいしい': 2, 'ビール': 1})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最初の単語の出現回数を数える\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_first_words_weights(three_words_count):\n",
    "    \"\"\"最初の単語を選択するためのデータを作成する\"\"\"\n",
    "    first_word_count = defaultdict(int)  # ❶ 値がint型のdefaultdictを作成\n",
    "\n",
    "    for three_words, count in three_words_count.items():\n",
    "        if three_words[0] == BEGIN:  # ❷ BEGINで始まるもののみを取り出す\n",
    "            next_word = three_words[1]\n",
    "            first_word_count[next_word] += count # ❸ 出現回数を加算\n",
    "            \n",
    "    return first_word_count\n",
    "\n",
    "get_first_words_weights(three_words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['おいしい', 'ビール'], [2, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 辞書データを単語と出現回数のリストにする\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_first_words_weights(three_words_count):\n",
    "    \"\"\"最初の単語を選択するための辞書データを作成する\"\"\"\n",
    "    first_word_count = defaultdict(int)\n",
    "\n",
    "    for three_words, count in three_words_count.items():\n",
    "        if three_words[0] == BEGIN:\n",
    "            next_word = three_words[1]\n",
    "            first_word_count[next_word] += count\n",
    "\n",
    "    words = []  # ❶ 単語と重み(出現回数)を格納するリスト\n",
    "    weights = []\n",
    "    for word, count in first_word_count.items():\n",
    "        words.append(word)  # ❷ 単語と重みをリストに追加\n",
    "        weights.append(count)\n",
    "            \n",
    "    return words, weights\n",
    "\n",
    "first_words, first_weights = get_first_words_weights(three_words_count)\n",
    "first_words, first_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文章を生成する\n",
    "\n",
    "import random\n",
    "\n",
    "def generate_text(fwords, fweights, markov_dict):\n",
    "    \"\"\"入力された辞書データを元に文章を生成する\"\"\"\n",
    "    first_word = random.choices(fwords, weights=fweights)[0]  # ❶ 最初の単語を取得\n",
    "    generate_words = [BEGIN, first_word]  # ❷ 文章生成用に単語を格納するリスト\n",
    "    while True:\n",
    "        pair = tuple(generate_words[-2:])  # ❸ 最後の2つの単語を取得\n",
    "        words = markov_dict[pair]['words']  # ❹ 次の単語と重みのリストを取得\n",
    "        weights = markov_dict[pair]['weights']\n",
    "        next_word = random.choices(words, weights=weights)[0]  # ❺ 次の単語を取得\n",
    "        if next_word == END:  # ❻ 文章が終了した場合はループを抜ける\n",
    "            break\n",
    "        generate_words.append(next_word)\n",
    "\n",
    "    return ''.join(generate_words[1:])  # ❼ 単語から文章を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "おいしいビールを飲もう\n",
      "おいしいビールを飲もう\n",
      "ビールを飲もう\n",
      "ビールを飲もう\n",
      "おいしいビールは生\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    text = generate_text(first_words, first_weights, markov_dict)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 34 文章データを取得して前処理をしましょう\n",
    "\n",
    "### 手順パート: 青空文庫からダウンロードした文章を前処理する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  # ❶requestsをインポート\n",
    "\n",
    "# 「人間失格」のファイルのURL\n",
    "url = 'https://www.aozora.gr.jp/cards/000035/files/301_ruby_5915.zip'\n",
    "r = requests.get(url)  # ❷ZipファイルのURLアクセス\n",
    "content = r.content  # ❸Zipファイルの中身を取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ningen_shikkaku.txt']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io  # ❶モジュールをインポート\n",
    "import zipfile\n",
    "\n",
    "f = io.BytesIO(content)  # ❷バイナリをファイルのように変換\n",
    "zipf = zipfile.ZipFile(f)  # ❸Zipファイルを開く\n",
    "namelist = zipf.namelist()  # ❹ファイル一覧を取得\n",
    "namelist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人間失格\r\n",
      "太宰治\r\n",
      "\r\n",
      "-------------------------------------------------------\r\n",
      "【テキスト中に現れる記号について】\r\n",
      "\r\n",
      "《》：ルビ\r\n",
      "（例）従姉妹《いとこ》\r\n",
      "\r\n",
      "｜：ルビの付く文字列の始まりを特定する記号\r\n",
      "（例）昔｜気質《かたぎ》\r\n",
      "\r\n",
      "［＃］：入力者注　主に外字の説明や、傍点の位置の指定\r\n",
      "（例）［＃３字下げ］はしがき［＃「はしがき」は大見出し］\r\n",
      "-------------------------------------------------------\r\n",
      "\r\n",
      "［＃３字下げ］はしがき［＃「はしがき」は大見出し］\r\n",
      "\r\n",
      "\r\n",
      "　私は、その男の写真を三葉、見たことがある。\r\n",
      "　一葉は、その男の、幼年時代、とでも言うべきであろうか、十歳前後かと推定される頃の写真であって、その子供が大勢の女のひとに取りかこまれ、（それは、その子供の姉たち、妹たち、それから、従姉妹《いとこ》たちかと想像される）庭園の池のほとりに、荒い縞の袴《はかま》をはいて立ち、首を三十度ほど左に傾け、醜く笑っている写真である。醜く？　けれども、鈍い人たち（\n"
     ]
    }
   ],
   "source": [
    "data = zipf.read(namelist[0])  # ❶Zipファイルを展開しデータを取り出す\n",
    "original_text = data.decode('Shift_JIS')  # ❷文字列にデコードする\n",
    "print(original_text[:500])  # ❸中身を確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文の数: 1177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['私はその男の写真を三葉見たことがある',\n",
       " '一葉はその男の幼年時代とでも言うべきであろうか十歳前後かと推定される頃の写真であってその子供が大勢の女のひとに取りかこまれ庭園の池のほとりに荒い縞の袴をはいて立ち首を三十度ほど左に傾け醜く笑っている写真である',\n",
       " '醜くけれども鈍い人たちは面白くも何とも無いような顔をして可愛い坊ちゃんですねといい加減なお世辞を言ってもまんざら空お世辞に聞えないくらいの謂わば通俗の可愛らしさみたいな影もその子供の笑顔に無いわけではないのだがしかしいささかでも美醜に就いての訓練を経て来たひとならひとめ見てすぐなんていやな子供だと頗る不快そうに呟き毛虫でも払いのける時のような手つきでその写真をほうり投げるかも知れない',\n",
       " 'まったくその子供の笑顔はよく見れば見るほど何とも知れずイヤな薄気味悪いものが感ぜられて来る',\n",
       " 'どだいそれは笑顔でない',\n",
       " 'この子は少しも笑ってはいないのだ',\n",
       " 'その証拠にはこの子は両方のこぶしを固く握って立っている',\n",
       " '人間はこぶしを固く握りながら笑えるものでは無いのである',\n",
       " '猿だ',\n",
       " '猿の笑顔だ']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "first_sentence = '私は、その男の写真を三葉、見たことがある。'\n",
    "last_sentence = '神様みたいないい子でした'\n",
    "_, text = original_text.split(first_sentence)  # ❶ 青空文庫の説明文を削除\n",
    "text, _ = text.split(last_sentence)\n",
    "text = first_sentence + text + last_sentence\n",
    "\n",
    "text = text.replace('｜', '').replace('　', '')  # ❷ '｜'' と '　' を削除\n",
    "text = re.sub('《\\w+》', '', text)  # ❷ルビを削除\n",
    "text = re.sub('［＃\\w+］', '', text)  # ❷注を削除\n",
    "text = text.replace('\\r', '').replace('\\n', '')  # ❷改行文字を削除\n",
    "text = re.sub('[、「」？]', '', text)  # ❷、「」 ？を削除\n",
    "text = re.sub('（\\w+）', '', text)  #  ❷（）と［］で囲まれている文を削除\n",
    "text = re.sub('［\\w+］', '', text)\n",
    "\n",
    "sentences = text.split('。')  # ❸。で文章を分割\n",
    "print('文の数:', len(sentences))\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 35 大量の文章データから文章生成用の辞書データを生成しましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:25<00:00,  1.98it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(50)):  # tqdm()で囲む\n",
    "    time.sleep(0.5)  # 0.5秒スリープ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 手順パート: 大量の文章データからマルコフ連鎖用辞書データを自動生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [00:54<00:00, 21.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30035"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "three_words_list = []\n",
    "for sentence in tqdm(sentences):  # ❶ tqdmで進捗バーを表示する\n",
    "    three_words_list += get_three_words_list(sentence)\n",
    "three_words_count = Counter(three_words_list)\n",
    "len(three_words_count)  # ❷ 3単語の組の種類を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19742\n",
      "498\n"
     ]
    }
   ],
   "source": [
    "markov_dict = generate_markov_dict(three_words_count)  # ❶ 文章生成用の辞書データを作成\n",
    "print(len(markov_dict))\n",
    "first_words, first_weights = get_first_words_weights(three_words_count)  # ❷最初の単語と出現数を取得\n",
    "print(len(first_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "私もその時堀木に教えられせっせと質屋がよいをはじめ一家中が激怒してやっぱり途方にくれてヒラメの家をたずね合ったりしましたがそれでもれいの空襲で焼け出されたのです\n",
      "自分は海辺の温泉地があったほど陰惨な絵が出来なかったら働いて……およそこの世で最も醜悪で下等で残酷な犯罪だとつねに彼を殺そうという覚悟は出来て悲惨な犯され方を他の者たちから窮屈でない\n",
      "しかし自分は口ごもってしまいました\n",
      "オントのアントは牛乳これは造血剤\n",
      "自分はその時それを全く現実として受取り恐怖している\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    sentence = generate_text(first_words, first_weights, markov_dict)\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 36 文章を自動生成するbotコマンドを作成しましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x03}q\\x00X\\x04\\x00\\x00\\x00nameq\\x01X\\x08\\x00\\x00\\x00takanoryq\\x02s.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# オブジェクトをpickle化する\n",
    "import pickle  # pickleモジュールをimport\n",
    "\n",
    "data = {'name': 'takanory'}\n",
    "pickled = pickle.dumps(data)  # dataオブジェクトをPickle化\n",
    "pickled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'takanory'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pickle化されたbytesオブジェクトから元に戻す\n",
    "data2 = pickle.loads(pickled)  # bytesオブジェクトをもとに戻す\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JSONでは対応していないオブジェクトがある\n",
    "import json\n",
    "jsoned = json.dumps((1, 2, 3))  # タプルがリストになる\n",
    "json.loads(jsoned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 手順パート: 文章生成（マルコフ）コマンドを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('markov-dict.pickle', 'wb') as f:  # ❶ファイルをバイナリ書き込みモードで開く\n",
    "    data = (first_words, first_weights, markov_dict)  # ❷3つのデータをタプルにまとめる\n",
    "    pickle.dump(data, f)  # ➌dataをpickle化して書き込む"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
